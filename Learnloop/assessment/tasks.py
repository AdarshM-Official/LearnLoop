# assessment_app/tasks.py

# NOTE: In a real production environment, you MUST set up Celery, Redis, 
# and a proper task queue system. This file uses synchronous execution 
# for demonstration purposes only.

import joblib
from django.conf import settings
from .models import CodeSubmission
from .extractor import extract_ml_features
import time # For simulating latency

# Path to the dummy model generated by simulate_ml_model.py
MODEL_PATH = 'seniority_model.joblib' 

def process_submission_synchronous(submission_id):
    """
    Synchronous function simulating a heavy Celery task: 
    1. Update status to PROCESSING.
    2. Extract code features (Code NLP).
    3. Run ML prediction.
    4. Generate feedback and update status to SUCCESS/ERROR.
    """
    try:
        submission = CodeSubmission.objects.get(pk=submission_id)
        
        # --- 1. Simulation Start ---
        submission.execution_status = 'PROCESSING'
        submission.save()
        time.sleep(2) # Simulate processing time

        # --- 2. Feature Extraction (Code NLP) ---
        # The feature_data dictionary and the vector for ML
        features, feature_vector = extract_ml_features(submission.code_snippet)
        
        if feature_vector is None:
            # Handle Syntax Error
            submission.execution_status = 'ERROR'
            submission.feedback = feature_vector # The error message
            submission.save()
            return
            
        submission.ml_features = features

        # --- 3. ML Prediction (Load and Predict) ---
        try:
            # Load the pre-trained model
            model = joblib.load(MODEL_PATH)
            
            # Predict seniority score (0.0 to 1.0)
            # Ensure the input is a 2D array: [[nodes, depth, complexity]]
            score = model.predict([feature_vector])[0]
            score = max(0.0, min(1.0, score)) # Clamp score between 0 and 1
            submission.seniority_score = float(f"{score:.4f}")

            # --- 4. Feedback Generation (Simple Rule Engine) ---
            if score >= 0.75:
                feedback_text = "Senior Level: Excellent code complexity management and efficiency detected."
            elif score >= 0.5:
                feedback_text = "Mid Level: Good structure, but consider reducing nesting or complexity."
            else:
                feedback_text = "Junior Level: Focus on code structure and utilizing Pythonic features to improve score."
            
            submission.feedback = feedback_text
            submission.execution_status = 'SUCCESS'

        except FileNotFoundError:
            submission.execution_status = 'ERROR'
            submission.feedback = "ML Model file (seniority_model.joblib) not found. Did you run simulate_ml_model.py?"
        except Exception as e:
            submission.execution_status = 'ERROR'
            submission.feedback = f"ML Prediction failed: {e}"
        
        submission.save()
        
    except CodeSubmission.DoesNotExist:
        print(f"Submission {submission_id} not found.")
    except Exception as e:
        print(f"General error processing submission {submission_id}: {e}")

# This function mimics the Celery interface for ease of development.
# Replace this with @shared_task and process_submission_synchronous content in production.
def process_submission(*args, **kwargs):
    """Simulated Celery task entry point."""
    return process_submission_synchronous(*args, **kwargs)

# Adding a mock delay method for use in views.py
process_submission.delay = process_submission
